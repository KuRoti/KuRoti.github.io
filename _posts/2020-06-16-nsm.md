---

title: "Neural State Machine"
date: 2020-06-16 10:26:28 -0400
categories: AI_Research
tags : GQA
layout: post

---

현재 연구중인 Neural State Machine의 논문입니다.

Neural State Machine, 이하 NSM은 GQA, VQA와 같은 visual question answering task를 위한 reasoning을 수행하는 모델입니다. NLP&AI 연구실의 학부 연구생 3명이 3월부터 GQA challenge를 위해 공부했고, NSM을 벤치마킹할 모델로 선정하였습니다.

visual reasoning task는 장면 사진을 보고 장면과 연관된 질문에 답하는 과제입니다. 

<img src="https://drive.google.com/uc?id=1BxtAsc7tT2OI_C1rKqCo1mT-TXGnJRkj" alt="info" style="zoom: 50%;" />

> Example of GQA question. 출처 : GQA 원 논문 [1]

GQA 원 논문에 의하면 GQA는 "a new dataset for real-world visual reasoning and compositional question answering" 입니다. 위 그림과 같은 real-world의 image와 해당 장면에 등장하는 사물들에 대한 질문이 입력으로 들어오면, 질문에 대한 답을 생성해내는 task입니다. 

Visual Question answering에 관련된 데이터셋들은 가상으로 생성된 이미지 데이터셋으로 강력한 ground truth를 제공해주는 CLEVR과 여기에 실제 이미지를 도입한 VQA, vqa를 개량한 GQA 등이 있으며, GQA 데이터셋을 기반으로 한 챌린지가 5월 말까지 진행중인데, 주최측은 지금 리뷰할 논문인 NSM의 저자인 Manning과 Hudson이 주축인 스탠포드입니다. 이 때문에 2020 GQA 챌린지에서는 이 두 저자가 연구한 NSM과 MAC의 성능이 Baseline으로 제시되죠. NSM의 경우는 ensemble 기법을 적용하지 않은 single-model의 성능 면에서 2019년 기준 State-of-Art를 달성한 모델이고, 현재까진 오픈소스를 제공하지 않고 있습니다.

[https://cs.stanford.edu/people/dorarad/gqa/](https://cs.stanford.edu/people/dorarad/gqa/)

위 링크가 현재 진행중인 GQA 챌린지의 메인 페이지입니다. GQA 데이터셋에 대한 자세한 정보를 얻을 수 있습니다. GQA 원 논문에서도 꾸준히 언급하는 내용이지만, GQA는 트레이닝 셋의 질문들이 기존의 VQA 버전보다 훨씬 balancing되어있어서 질문의 편향을 개선한 점이 특징입니다.



Neural state machine이 주목하는 개념은 인간 인지의 'abstraction'과 'generalization' 능력입니다. 

![nsm](https://drive.google.com/uc?id=1cr3_czkMPi0MKtJbbnj0dskMsnuOgJoC)

> NSM의 동작 구조. 출처 : NSM 원논문 [2]

NSM은 이름에서도 짐작할 수 있듯이 symbolic model을 지향합니다. 

![gqa2](https://drive.google.com/uc?id=1qGDrzOTT6WPz6bcsK0KgQguHx0sWDwHw)

> NSM의 question answering의 예시. 출처 : NSM 원논문 [2]



저희는 3개월간 NSM과 MAC, GQA 등에 관한 논문을 읽고 NSM을 벤치마킹하는 작업을 진행했습니다. Notion, Colab을 이용해 협력하였고 2달간 주 4회 미팅을 가지며 코딩 협업을 진행했습니다. 현재 NSM에 사용될 데이터를 preprocessing하기 위한 리소스를 확보중이며 NSM 모델에 대한 코딩은 어느 정도 완성이 되었습니다. 7월 중으로는 실질적인 모델 개선과 원 논문의 성능 재현을 위한 작업을 진행할 예정입니다.

  

>    다음은 3~6월동안 진행한 세부 기록입니다.

GQA Challenge의 dev-버전 데이터 제출 기한이 5월 24일까지였기에 4월 중에는 모델의 벤치마킹을 완료해 기존의 성능을 구현하는 작업을, 5월에는 모델의 개량을 진행하는 것을 목표로 프로젝트를 진행하게 되었습니다. 3월에 이론적 배경에 대한 스터디를 진행하고 NSM과 MAC을 공부하였기에, 4월은 본격적인 코딩 작업을 분담하여 진행하였습니다.

4월 1주차에는 NSM을 프로젝트의 목표 모델로 선정하였습니다. GQA 2020 LeaderBoard에 주최측이 제공한 Baseline 성능이 NSM의 성능이기도 하고, MAC의 경우에는 Knowledge Base라는 이미지 정보를 필요하는 모델이기 때문에 이미지 feature를 모델이 학습해야 해서 방대한 리소스를 필요로 할 것이라 예측되어 리소스가 부족한 환경이기에 NSM을 선정하게 되었습니다. NSM은 Image나 Image이 Extracted Feature를 입력으로 받는 형태가 아니라, 이미지의 object와 relation, attribute를 담는 자료구조인 SceneGraph를 입력으로 받기에 상대적으로 리소스를 적게 소모할 것이라 판단했습니다. Image로부터 SceneGraph를 얻는 작업은 Pretrain된 기존 모델을 사용하고자 했습니다.    

4월 둘째주까지는 본격적인 코딩 작업은 진행하지 못하고 NSM 이해에 시간을 투자했습니다. NSM이 최신 논문이기에 오픈 소스가 공개되어있지 않고 참고할만한 자료는 수도코드 형태로 개략적인 틀만 짜여져 있는 한 github 소스가 전부였습니다. 또한 NSM 논문 자체가 동작을 이해하기 위해 이해를 많이 요구하는 논문이었기에 세부적인 알고리즘에 대해 팀원 모두가 이해를 갖추기까지 많은 공부와 의견 공유가 필요했습니다. 이에 2주차에는 기존 출처미상의 pytorch 수도코드에 주석을 달며 NSM 알고리즘의 구성을 이해하고, Kakao-Brain 팀의 Daft-Mac 오픈소스와 GQA측의 MAC Baseline 코드를 읽으며 공부를 진행하였습니다.  

4월 3주차부터는 본격적인 코딩 작업을 진행하였습니다. input-preprocessing, Concept Voca Building, NSM 으로 파트를 3개로 나누어 병렬적으로 업무를 진행하였습니다. 저는 Input 데이터 전처리를 진행하였습니다. NSM 원논문에서는 Graph-RCNN이라는 네트워크를 implement하여 Image로부터 SceneGraph를 생성하였는데, 이때 인용한 Graph-Rcnn의 논문 저자의 Github 코드를 기반으로 Scene graph generation을 수행하려 했으나 리소스와 호환성 등의 문제로 작동이 되지 않아 GQA측에서 훈련용으로 제공하는 Scene Graph를 사용하기로 결정했습니다.

4월 4주차까지는 Input 전처리에 집중했습니다. NSM은 attribute와 object, Relation 정보 모두에 probability distribution 정보를 요구하지만, 저희가 가진 Scenegraph 데이터에는 binary로 특정 feature의 존재 여부만 알 수 있을 뿐, 실수 확률 분포를 알 수 없었습니다. 이에 softmax classifier를 훈련시켜 각 attribute를 label로 삼아 object feature로부터 attribute distribution을 추출해내는 2layer fully connected network를 이용하여 데이터 전처리를 진행하였습니다.

5월 1주차에는 실제 데이터를 모델에 넣고 훈련시키기 위한 조율이 진행되었습니다. NSM 모델 내부에서 쓰이는 Tensor들의 차원을 결정하기 위해 논의에 시간을 많이 할애하였습니다. 가장 주요한 문제는 NSM에 필요한 데이터였습니다. 리소스의 문제로 Scenegraph generation을 제대로 거칠 수 없어 임시 방편으로 훈련용으로 제공된 scenegraph에서 attribute distribution을 추출해서 사용했지만, GQA측에서 제공한 Scenegraph는 사람이 손으로 작성한 크라우드소싱 데이터이고 GQA 측에서 제공한 object feature는 MASK RCNN으로 추출한 결과이기 때문에, Scenegraph에서 등장하는 object가 object feature데이터에 존재하지 않는 경우가 너무 많았습니다. 따라서 attribute distribution의 정확도가 낮았고, 그보다 주요한 문제는 7x7의 map으로 주어진 spatial feature 데이터와 object들의 feature로 주어진 데이터가 서로 호환되지 않아 scenegraph에 등장하지 않는 단어에 대해서는 attribute distribution을 추출할 수가 없다는 것이었습니다. 따라서 사용 가능한 scene과 attribute의 개수가 큰 폭으로 감소했습니다.

5월 2주차와 3주차에는 DAFT MAC 코드의 뼈대를 이용해 NSM을 실행시키는데 성공했습니다. train을 위한 데이터는 GQA에서 제공한 데이터를 정제해 사용하였고, 1만여개의 scene에 대해 question을 매칭하여 데이터를 json으로 저장했습니다. 실행 결과 30%대의 낮은 accuracy가 나왔고 대부분의 응답이 binary로 편향되어 나오는 것을 확인했습니다. 이에 모델 수정과 최적화를 위한 논의를 진행했습니다.

2주차까지 대부분의 작업은 pc를 사용할 수 있는 카페에서 gtx1080과 colab gpu를 이용해 진행했으나, 2주차부터 연구실에 2대의 데스크탑을 지원받아 linux 환경에서 작업을 진행할 수 있었습니다. 하지만 gpu 사용과정을 최적화하지 않아 gpu 메모리가 부족해 train을 매우 적은 데이터에 한해서만 실행할 수 있었다는 단점을 발견하였고, 3주차에는 dataloader를 이용한 메모리 최적화 작업을 거쳤습니다.

​    10월로 test challenge가 연기됨에 따라 NSM 구현을 더 보완하여 진행할 예정입니다.



### Reference

\[1\] Hudson, D. A., & Manning, C. D. (2019). GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering. arXiv preprint arXiv:1902.09506

\[2\] Hudson, D., & Manning, C. D. (2019). Learning by abstraction: The neural state machine. In Advances in Neural Information Processing Systems (pp. 5901-5914).